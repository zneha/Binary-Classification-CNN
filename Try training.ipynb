{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras import callbacks\n",
    "import time\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "DEV = False\n",
    "# DEV = True\n",
    "argvs = sys.argv\n",
    "argc = len(argvs)\n",
    "\n",
    "if argc > 1 and (argvs[1] == \"--development\" or argvs[1] == \"-d\"):\n",
    "  DEV = True\n",
    "\n",
    "if DEV:\n",
    "  epochs = 2\n",
    "else:\n",
    "  epochs = 20\n",
    "\n",
    "train_data_path = r\"Z:\\User Data\\Neha reddy\\ECG\\Prelim AIM\\Data\\Machine Learning\\CNN\\train\"\n",
    "validation_data_path = r\"Z:\\User Data\\Neha reddy\\ECG\\Prelim AIM\\Data\\Machine Learning\\CNN\\validation\"\n",
    "\n",
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "img_width, img_height = 16,16 \n",
    "batch_size = 32\n",
    "samples_per_epoch = 1000\n",
    "validation_steps = 300\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 64\n",
    "conv1_size = 3\n",
    "conv2_size = 2\n",
    "pool_size = 2\n",
    "classes_num = 2\n",
    "lr = 0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0827 12:49:20.276707 11564 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(16, 16, 3..., padding=\"same\")`\n",
      "  \n",
      "W0827 12:49:20.289681 11564 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0827 12:49:20.291670 11564 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0827 12:49:20.302634 11564 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (2, 2), padding=\"same\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  \n",
      "W0827 12:49:20.311617 11564 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0827 12:49:20.312617 11564 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0827 12:49:20.353502 11564 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0827 12:49:20.376416 11564 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0827 12:49:20.382425 11564 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 220821 images belonging to 2 classes.\n",
      "Found 220820 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=20, validation_data=<keras_pre..., callbacks=[<keras.ca..., validation_steps=300, steps_per_epoch=31)`\n",
      "W0827 12:50:14.311073 11564 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0827 12:50:14.311073 11564 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31/31 [==============================] - 166s 5s/step - loss: 0.6357 - acc: 0.6532 - val_loss: 0.4176 - val_acc: 0.8229\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 162s 5s/step - loss: 0.4551 - acc: 0.8327 - val_loss: 0.3601 - val_acc: 0.8258\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 165s 5s/step - loss: 0.4471 - acc: 0.8317 - val_loss: 0.3676 - val_acc: 0.8214\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 157s 5s/step - loss: 0.4310 - acc: 0.8337 - val_loss: 0.3469 - val_acc: 0.8331\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 159s 5s/step - loss: 0.4305 - acc: 0.8347 - val_loss: 0.3464 - val_acc: 0.8326\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 158s 5s/step - loss: 0.4373 - acc: 0.8317 - val_loss: 0.3566 - val_acc: 0.8230\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 137s 4s/step - loss: 0.4429 - acc: 0.8105 - val_loss: 0.3446 - val_acc: 0.8283\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 154s 5s/step - loss: 0.4080 - acc: 0.8427 - val_loss: 0.3541 - val_acc: 0.8207\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 145s 5s/step - loss: 0.4211 - acc: 0.8306 - val_loss: 0.3373 - val_acc: 0.8282\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 168s 5s/step - loss: 0.4248 - acc: 0.8266 - val_loss: 0.3361 - val_acc: 0.8256\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 153s 5s/step - loss: 0.4271 - acc: 0.8165 - val_loss: 0.3305 - val_acc: 0.8270\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 149s 5s/step - loss: 0.4170 - acc: 0.8206 - val_loss: 0.3284 - val_acc: 0.8189\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 162s 5s/step - loss: 0.4050 - acc: 0.8216 - val_loss: 0.3184 - val_acc: 0.8237\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 165s 5s/step - loss: 0.3652 - acc: 0.8427 - val_loss: 0.3179 - val_acc: 0.8193\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 167s 5s/step - loss: 0.3840 - acc: 0.8286 - val_loss: 0.2871 - val_acc: 0.8301\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 166s 5s/step - loss: 0.3831 - acc: 0.8266 - val_loss: 0.2934 - val_acc: 0.8191\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 169s 5s/step - loss: 0.3894 - acc: 0.8115 - val_loss: 0.2749 - val_acc: 0.8217\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 185s 6s/step - loss: 0.3832 - acc: 0.8115 - val_loss: 0.2576 - val_acc: 0.8478\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 227s 7s/step - loss: 0.3420 - acc: 0.8367 - val_loss: 0.2439 - val_acc: 0.8753\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 160s 5s/step - loss: 0.3633 - acc: 0.8236 - val_loss: 0.2368 - val_acc: 0.8851\n",
      "Execution Time: 55.503728075822195 minutes\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters1, conv1_size, conv1_size, border_mode =\"same\", input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "model.add(Convolution2D(nb_filters2, conv2_size, conv2_size, border_mode =\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size), dim_ordering='th'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(classes_num, activation='softmax'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',  NEHA\n",
    "#               optimizer=optimizers.RMSprop(lr=lr),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "opt = SGD(lr=0.001, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# return model\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "\"\"\"\n",
    "Tensorboard log\n",
    "\"\"\"\n",
    "log_dir = './tf-log/'\n",
    "tb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
    "cbks = [tb_cb]\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=samples_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=cbks,\n",
    "    validation_steps=validation_steps)\n",
    "\n",
    "target_dir = './models/'\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "model.save('./models/model.h5')\n",
    "model.save_weights('./models/weights.h5')\n",
    "\n",
    "#Calculate execution time\n",
    "end = time.time()\n",
    "dur = end-start\n",
    "\n",
    "if dur<60:\n",
    "    print(\"Execution Time:\",dur,\"seconds\")\n",
    "elif dur>60 and dur<3600:\n",
    "    dur=dur/60\n",
    "    print(\"Execution Time:\",dur,\"minutes\")\n",
    "else:\n",
    "    dur=dur/(60*60)\n",
    "    print(\"Execution Time:\",dur,\"hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
